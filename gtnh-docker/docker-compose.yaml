name: gtnh
services:
  tailscale: # VPN service for connections
    image: tailscale/tailscale:latest
    container_name: gtnh_tailscale
    # Hostname for the "machine" which is the container running. appears as the name of the machine in Tailscale
    hostname: gtnh
    environment:
      # Tailscale auth key from their script
      - TS_AUTHKEY=${TS_AUTHKEY}
      - TS_ROUTES=${TS_ROUTE}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
    volumes:
      # Required by Tailscale
      - ./tailscale/state:/var/lib/tailscale
    devices: # it seems that on newer docker compose versions it needs to be in devices
      - /dev/net/tun:/dev/net/tun # for VPN tunnel without userspace
    cap_add:
      # Also required by Tailscale (permissions)
      - net_admin
      - sys_module
    restart: ${RESTART_POLICY}
    healthcheck:
      test: tailscale status --peers=false --json | grep -q 'Online.*true'
    networks:
      frontend:
        ipv4_address: ${TS_IP}

  gtnh-server: # GTNH minecraft server
    build:
      context: ./gtnh-server
      dockerfile: Dockerfile
    container_name: gtnh_server
    depends_on:
      tailscale: # Tailscale needs to be running so the server starts (it's not accesible otherwise)
        condition: service_healthy
    volumes:
      - ./gtnh-server/minecraft:/minecraft
    restart: ${RESTART_POLICY}
    networks:
      frontend:
          ipv4_address: ${GTNHS_IP}
      backend:
          ipv4_address: 10.21.31.3

  gtoverseer-frontend: # Streamlit web interface
    build:
      context: ./gtoverseer-frontend
      dockerfile: Dockerfile
    container_name: GTOverseer_frontend
    depends_on:
      gtoverseer-backend:
        condition: service_started
      tailscale:
        condition: service_healthy
    restart: ${RESTART_POLICY}
    environment:
      ADMIN_USERNAME: "${ADMIN_USERNAME}"
    networks:
      backend:
        ipv4_address: 10.21.31.9
      frontend:
        ipv4_address: ${GTO_FRONTEND_IP}

  gtoverseer-backend: # Python REST API
    build:
      context: ./gtoverseer-backend
      dockerfile: Dockerfile
    container_name: GTOverseer_backend
    depends_on:
      gtoverseer-db:
        condition: service_started
      tailscale:
        condition: service_healthy
    restart: ${RESTART_POLICY}
    environment:
      DBNAME: "postgres"
      USER: "gtoverseer_app"
      PASSWORD: "${GTOVERSEER_POSTGRES_PASSWORD}"
      HOST: "10.22.32.4"
      PORT: "${POSTGRES_PORT}"
      ADMIN_USERNAME: "${ADMIN_USERNAME}"
      ADMIN_EMAIL: "${ADMIN_EMAIL}"
      ADMIN_PASSWORD: "${ADMIN_PASSWORD}"
      UPDATE_RATE: "${GTO_DEFAULT_UPDATE_RATE}"
      REINITIALIZATION_RATE: "${GTO_DEFAULT_REINITIALIZATION_RATE}"
    networks:
      backend:
        ipv4_address: 10.21.31.5
      services:
        ipv4_address: 10.22.32.5

  gtoverseer-db: # Postgres database
    build:
      context: ./postgres
      dockerfile: Dockerfile
      args:
        PGDATA: "${POSTGRES_DATA_DIRECTORY}"
    container_name: GTOverseer_postgre
    restart: ${RESTART_POLICY}
    depends_on:
      tailscale:
        condition: service_healthy
    environment:
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      GTOVERSEER_POSTGRES_PASSWORD: "${GTOVERSEER_POSTGRES_PASSWORD}"
      PGDATA: "${POSTGRES_DATA_DIRECTORY}"
    mem_limit: ${POSTGRES_MEM_LIMIT}
    mem_reservation: ${POSTGRES_MEM_RESERVATION}
    command: >-
      postgres
      -c hba_file='/etc/postgresql/pg_hba.conf'
      -c max_connections=${max_connections}
      -c shared_buffers=${shared_buffers}
      -c effective_cache_size=${effective_cache_size}
      -c maintenance_work_mem=${maintenance_work_mem}
      -c checkpoint_completion_target=${checkpoint_completion_target}
      -c wal_buffers=${wal_buffers}
      -c default_statistics_target=${default_statistics_target}
      -c random_page_cost=${random_page_cost}
      -c effective_io_concurrency=${effective_io_concurrency}
      -c work_mem=${work_mem}
      -c huge_pages=${huge_pages}
      -c min_wal_size=${min_wal_size}
      -c max_wal_size=${max_wal_size}
      -c wal_level=${wal_level}
      -c max_wal_senders=${max_wal_senders}
      -c logging_collector='off'
      -c log_destination='stderr'
      -c log_filename='postgresql-%Y-%m-%d_%H%M%S.log'
      -c log_truncate_on_rotation='off'
      -c log_min_messages='warning'
      -c log_min_error_statement='error'
      -c log_line_prefix='%m [%p]'
      -c log_statement='ddl'
      -c log_line_prefix='%m [%p]'
      -c unix_socket_permissions='0770'
    volumes:
      - ${POSTGRES_DATA_DIRECTORY_LOCAL}:${POSTGRES_DATA_DIRECTORY}
    ports:
      - "127.0.0.1:${POSTGRES_PORT}:5432"
    networks:
      services:
        ipv4_address: 10.22.32.4

networks:
  # For external communication (through tailscale)
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: ${TS_ROUTE}

  # For communication between the server, frontend and backend
  backend:
    driver: bridge
    ipam:
      config:
        - subnet: 10.21.31.0/24
    internal: true

  # Internal communication between the database and backend
  services:
    driver: bridge
    ipam:
      config:
        - subnet: 10.22.32.0/24
    internal: true